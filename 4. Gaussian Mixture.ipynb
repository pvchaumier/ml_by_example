{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gaussian Mixture\n",
    "\n",
    "One can see this unsipervised learning model as a \"soft\" version of K-Means. In K-Means, for each cluster, the datapoints were separated between belongs to or does not belong to the cluster. Now, what we want is a probability to belong to the cluster. In other words, given a datapoint we would like to compute its probability of belonging to each cluster. For instance, if we look for two clusters, one datapoint will have probability 0.2 to belong to cluster 1 and probability 0.8 of belonging to cluster 2.\n",
    "\n",
    "As in K-Means, one needs to provide the number of cluster looked for. There exists some extension that are able in certain cases to detect whether the number of cluster given is too low or too high but things will be kept simple for now.\n",
    "\n",
    "In order to do find the different probability, the clusters are modelised by probability distributions. For Gaussian Mixture, the proba are modelised, as the name indicates, by multivariate gaussians. Each cluster is thus supposed to follow a probability distribution of $N(\\mu, \\Sigma)$ and the whole idea is to find those $\\mu$ and $\\Sigma$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import random\n",
    "\n",
    "from numpy import matlib\n",
    "\n",
    "from scipy.stats import multivariate_normal\n",
    "from scipy.misc import logsumexp\n",
    "\n",
    "from fct import normalize_min_max, plot_2d, plot_multivariate_ellipse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## -------------------- Gaussian Multivariate  -------------------\n",
    "\n",
    "def initiate_var(data, K, sigma):\n",
    "    \"\"\"Returns the priors, means and covariance matrices intialized.\n",
    "\n",
    "    prior: all equal\n",
    "    means: randomly generated within the limits of the data\n",
    "    covariance matrices: identity multiplied by a same sigma\n",
    "    \"\"\"\n",
    "\n",
    "    # all prior are equal at first\n",
    "    priors = np.ones(K) / K\n",
    "\n",
    "    # define limits of the data\n",
    "    minis = [np.amin(data[:,j]) for j in range(data.shape[1])]\n",
    "    maxis = [np.amax(data[:,j]) for j in range(data.shape[1])]\n",
    "    # Generate random centers\n",
    "    means = np.array([[random.random() * maxis[j] + minis[j]\n",
    "                        for j in range(data.shape[1])]\n",
    "                        for k in range(K)])\n",
    "\n",
    "    # covariance matrices are identity matrices at first\n",
    "    covs = [sigma * np.matlib.identity(data.shape[1]) for k in range(K)]\n",
    "\n",
    "    return priors, means, covs\n",
    "\n",
    "\n",
    "def update_gammas(data, K, means, covs, priors):\n",
    "    \"\"\"Build and returns the gammas matrix and the current multivariates.\"\"\"\n",
    "\n",
    "    # Definition of the multivariates using the means and covs matrices\n",
    "    mlvts = [multivariate_normal(mean=means[k], cov=covs[k]) for k in range(K)]\n",
    "    # calculate the probability the datapoints using the Probability Density \n",
    "    # Function (pdf)\n",
    "    mlvts_pdf = [mlvts[k].pdf(data) for k in range(K)]\n",
    "\n",
    "    # Matrix (K, N) each element is with the notation of the course\n",
    "    # log(Pi_k * N(X_i | mu_k, Sigma_k))\n",
    "    log_gammas = [np.log(priors[k] * mlvts_pdf[k]) for k in range(K)]\n",
    "\n",
    "    # We sum other the N elements of the line\n",
    "    sum_log_gamma = [logsumexp(np.asmatrix(log_gammas).T[n])\n",
    "                     for n in range(data.shape[0])]\n",
    "\n",
    "    # gammas is actually the matrix of the log of the gammas\n",
    "    gammas = np.asmatrix([log_gammas[k] - sum_log_gamma for k in range(K)])\n",
    "\n",
    "    return gammas, mlvts\n",
    "\n",
    "\n",
    "def update_mean(data, K, gammas):\n",
    "    \"\"\"Returns the new means calculated using the gammas.\"\"\"\n",
    "\n",
    "    ones = np.ones(data.shape)\n",
    "    up = np.dot(np.exp(gammas), data)\n",
    "    down = np.dot(np.exp(gammas), ones)\n",
    "    return np.array([(up[k] / down[k]).A1 for k in range(K)])\n",
    "\n",
    "\n",
    "def update_cov(data, K, means, gammas):\n",
    "    \"\"\"Returns the new covariance matrices as a list of matrices.\"\"\"\n",
    "\n",
    "    covs = []\n",
    "    ones = np.ones(data.shape)\n",
    "    sum_gammas = np.dot(np.exp(gammas), ones)\n",
    "    for k in range(K):\n",
    "        # matrix to multiply with the (data - mu) matrix element by element\n",
    "        # (gamma_k_1 gamma_k_1 .. gamma_k_1)\n",
    "        # (gamma_k_2 gamma_k_2 .. gamma_k_2)\n",
    "        # (  ...       ...     ..    ...   )\n",
    "        # (gamma_k_N gamma_k_2 .. gamma_k_N)\n",
    "        gammas_k = np.dot(np.exp(gammas[k]).T,\n",
    "                          np.matlib.ones((1, data.shape[1])))\n",
    "        # matrix to be substracted from the data matrix\n",
    "        # (mu_k_1 mu_k_2 .. mu_k_d)\n",
    "        # (mu_k_1 mu_k_2 .. mu_k_d)\n",
    "        # (  ...    ...  ..  ...  )\n",
    "        # (mu_k_1 mu_k_2 .. mu_k_d)\n",
    "        mu = np.dot(np.matlib.ones((data.shape[0], 1)),\n",
    "                    np.asmatrix(means[k]))\n",
    "        cov = np.dot((np.asmatrix(data) - mu).T,\n",
    "                      np.multiply(gammas_k, data - mu))\n",
    "        cov /= sum_gammas[k]\n",
    "        covs.append(cov)\n",
    "    return covs\n",
    "\n",
    "\n",
    "def update_prior(data, gammas):\n",
    "    \"\"\"Returns a numpy array with the prior for each multivariate.\"\"\"\n",
    "\n",
    "    ones = np.matlib.ones(data.shape[0]).T\n",
    "    sum_gammas = np.dot(np.exp(gammas), ones)\n",
    "    sum_gammas = np.array([np.sum(np.exp(gammas[k])) for k in range(K)])\n",
    "    return sum_gammas / data.shape[0]\n",
    "\n",
    "\n",
    "def gmm(data, K):\n",
    "    \"\"\"The Gaussian Mixture Model function.\"\"\"\n",
    "\n",
    "    # Initial variable\n",
    "    sigma = 0.1\n",
    "    priors, means, covs = initiate_var(data, K, sigma)\n",
    "    priors_old = np.ones(K)\n",
    "\n",
    "    # First step\n",
    "    gammas, m = update_gammas(data, K, means, covs, priors)\n",
    "\n",
    "    iteration = 0\n",
    "    while not np.array_equal(np.around(priors, decimals=6),\n",
    "                             np.around(priors_old, decimals=6)):\n",
    "        means = update_mean(data, K, gammas)\n",
    "        covs = update_cov(data, K, means, gammas)\n",
    "        priors_old = priors\n",
    "        priors = update_prior(data, gammas)\n",
    "        gammas_old = gammas\n",
    "        gammas, m = update_gammas(data, K, means, covs, priors)\n",
    "\n",
    "        plt.clf()\n",
    "        title = 'Iteration nÂ°' + str(iteration)\n",
    "        iteration += 1\n",
    "        plot_2d(data, color='b', title=title)\n",
    "        plot_multivariate_ellipse(m, K)\n",
    "        plt.show(block=False)\n",
    "        plt.pause(0.0001)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## -------------------- Data  -------------------\n",
    "\n",
    "k = 2\n",
    "data = pd.read_csv('datasets/data_clustering.csv')\n",
    "data = np.array(data)\n",
    "\n",
    "\n",
    "## -------------------- GMM in use  -------------------\n",
    "\n",
    "normalize_min_max(data, k)\n",
    "K = 4\n",
    "gmm(data, K)\n",
    "\n",
    "plt.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
