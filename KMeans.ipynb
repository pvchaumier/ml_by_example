{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K-Means\n",
    "\n",
    "## Goal\n",
    "\n",
    "Given a set of unlabelled data, the objective is to find clusters within it (groups of data that are \"similar\" for a given distance, usually the euclidian distance). Normally, this problem is NP-hard but the K-means algorithm use an iterative approach that finds a local minimum (usually global, but if you run it multiple times, you might see that it sometimes converges to a false solution).\n",
    "\n",
    "K-Means, given a set of n data and the number of the clusters we think there is, returns the center and/or the data separated in clusters. In this implementation, it only returns the center of the clusters.\n",
    "\n",
    "As you may have already understand, the main drawback of this algorithm is that you have to specify the k beforehand.\n",
    "\n",
    "K-means works by alterning the two following steps:\n",
    "- compute the centers of the clusters (for the first step, they are taken at random within the dataset, after that, they are defined as the barycenter/mean of the clusters)\n",
    "- build the clusters from the center. A data belong to the cluster defined by the closest center\n",
    "\n",
    "To explain it more sequentially, it begins by choosing at random k centers. Then it seperates the dataset into clusters by computing the distance of all points to all center and saying that a datapoint belongs to the closest center. After that, it computes the mean of the clusters (not that this will change the position of the center and thus the distances to the other points) to find new centers and so on and so forth. \n",
    "\n",
    "If this is unclear (as I am sure it will be if you do not already know the algorithm), go check the [wikipedia page](https://en.wikipedia.org/wiki/K-means_clustering) that contains very well made visual examples of this process.\n",
    "\n",
    "\n",
    "## Implementation\n",
    "\n",
    "I could plot the successive step within the notebook. So a new window with the plot will open when executing the last cell. If it does not appear, it might be hidden behind your current open window, reducing the size of it may allow you to see the plots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import time\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from fct import normalize_min_max, plot_2d, plot_clusters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Algorithm\n",
    "\n",
    "Here are the different elements:\n",
    "- D is the distance matrix, each row correspond to one datapoint and each column to one center $D[i, j] = distance(datapoint_i, center_j)$\n",
    "- G is the matrix that specifies to which center belongs each datapoint. As for the distance matrix, the rows are for the datapoints and the columns are for the centers. $G[i, j] = 0$ if $center_j$ is the closest center to $datapoint_i$\n",
    "\n",
    "The algorithm runs while "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_d(datas, centers):\n",
    "    \"\"\"Return a 2D-numpy array of the distances between each\n",
    "    point in the dataset and the centers.\n",
    "    \"\"\"\n",
    "    # the distance matrix is d\n",
    "    d = []\n",
    "    for center in centers:\n",
    "        # the list of distances from one center to all the points in the\n",
    "        # dataset\n",
    "        dist = []\n",
    "        for i in range(datas.shape[0]):\n",
    "            dist.append(np.linalg.norm(datas[i] - center))\n",
    "        d.append(dist)\n",
    "    return np.array(d)\n",
    "\n",
    "def build_g(distances):\n",
    "    \"\"\"Return a 2D-numpy array of 0s and 1s that determines\n",
    "    to which center belong each point in the dataset.\n",
    "    \"\"\"\n",
    "    # k is the number of clusters we look for\n",
    "    k = distances.shape[0]\n",
    "    # g is the matrix of affiliation\n",
    "    g = []\n",
    "    for i in range(distances.shape[1]):\n",
    "        # gg elements is 1 only if the point belongs to the\n",
    "        # corresponding center, else it is 0\n",
    "        gg = [0] * k\n",
    "        # computes which center is the closest to the point\n",
    "        gg[distances[:,i].argmin()] = 1\n",
    "        g.append(gg)\n",
    "    return np.array(g).T\n",
    "\n",
    "def build_clusters(datas, G):\n",
    "    \"\"\"Return a list of clusters (lists as well) of points from the dataset.\"\"\"\n",
    "    k = G.shape[0]\n",
    "    clusters = [[] for i in range(k)]\n",
    "    for i in range(G.shape[0]):\n",
    "        for j in range(G.shape[1]):\n",
    "            if G[i][j] == 1:\n",
    "                clusters[i].append(datas[j])\n",
    "    return clusters\n",
    "\n",
    "def new_centers(clusters):\n",
    "    \"\"\"Return a list of points drawn as the barycenter of each new cluster.\"\"\"\n",
    "    centers = []\n",
    "    for cluster in clusters:\n",
    "        # the center of each cluster is its barycenter\n",
    "        center = np.mean(cluster, axis=0)\n",
    "        centers.append(center)\n",
    "    return centers\n",
    "\n",
    "def k_means(datas, k):\n",
    "    \"\"\"Return the centers of the clusters found after the iterative process.\"\"\"\n",
    "    # The initial centers are taken at random within the dataset\n",
    "    centers = random.sample(list(datas), k)\n",
    "    D = build_d(datas, centers)\n",
    "    G = build_g(D)\n",
    "    clusters = build_clusters(datas, G)\n",
    "    centers_new = new_centers(clusters)\n",
    "\n",
    "    # while the new centers are not equal to the previous ones (it means the\n",
    "    # situation is not stationary) then we keep iterating\n",
    "    while not np.array_equal(np.array(centers), np.array(centers_new)):\n",
    "        centers = np.copy(centers_new)\n",
    "        D = build_d(datas, centers)\n",
    "        G = build_g(D)\n",
    "        clusters = build_clusters(datas, G)\n",
    "        centers_new = new_centers(clusters)\n",
    "        \n",
    "        # plot the clusters with different colors. The center are plotted\n",
    "        # in blue\n",
    "        plt.clf()\n",
    "        plot_clusters(clusters, k)\n",
    "        X = [center[0] for center in centers]\n",
    "        Y = [center[1] for center in centers]\n",
    "        plt.scatter(X,Y)\n",
    "        plt.show(block=False)\n",
    "        plt.pause(0.01)\n",
    "\n",
    "    plt.close()\n",
    "    return centers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Application"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dimension = 2\n",
    "datas = pd.read_csv('datasets/data_clustering.csv')\n",
    "datas = np.array(datas)\n",
    "normalize_min_max(datas, dimension)\n",
    "\n",
    "# You can play with the number of clusters K to \n",
    "# see how it affects the result.\n",
    "K = 4\n",
    "centers = k_means(datas, K)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
